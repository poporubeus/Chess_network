{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOaHnWVV9RwB"
      },
      "source": [
        "In questo notebook definisco le funzioni necessarie a:\n",
        "\n",
        "    1. Creare un grafo\n",
        "    2. Ottenere le varie misure (diametro, betwennes, numero community etc) dal grafo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyH5VsEG1AIk"
      },
      "source": [
        "num nodi, num link, diametro, num commuty, num elementi biggest comm, average degree, plot degree vs betwennes (estrai coefficiente correlazione e plottalo in funzione del tempo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCSpNdig9sXZ"
      },
      "outputs": [],
      "source": [
        "!pip install igraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVFavbCt2LPP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNvOiYWOIvub"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI9Bx-c2N7ew",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import igraph as ig\n",
        "import community\n",
        "import community.community_louvain as community_louvain\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt1h_HeX-VSG"
      },
      "outputs": [],
      "source": [
        "#ritorna il network creato partendo da un df pulito\n",
        "def create_network_from_dataframe(df):\n",
        "   G = nx.from_pandas_edgelist(df, source='White', target='Black')\n",
        "   return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYSaoIS3_YJm"
      },
      "outputs": [],
      "source": [
        "def network_diameter(G):\n",
        "   return nx.diameter(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFPeP2Ey_bIc"
      },
      "outputs": [],
      "source": [
        "def central_cluster_of_network(G):\n",
        "   largest_cc = max(nx.connected_components(G), key=len)\n",
        "   cc = G.subgraph(largest_cc).copy()\n",
        "   return cc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiDHlzmH_g6L"
      },
      "outputs": [],
      "source": [
        " #questa ritorna 2 liste: la lista delle degree dei giocatori e la lista dei nomi dei giocatori\n",
        "def degree_list(G):\n",
        "   degree = dict(G.degree())\n",
        "   names_list=list(degree.keys())\n",
        "   degree_list=list(degree.values())\n",
        "   return degree_list,names_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vPC2bIt_rsx"
      },
      "outputs": [],
      "source": [
        "#questa prende il network e la bool che dice se vogliamo la betwenness normalizzata o no e ritorna 2 liste:\n",
        "#la lista delle betwenness e la lista dei nomi dei giocatori\n",
        "\n",
        "def betweenness_list(G,normalized):\n",
        "   bet=dict(nx.betweenness_centrality(G,normalized=normalized))\n",
        "   names_list=list(bet.keys())\n",
        "   bet_list=list(bet.values())\n",
        "   return bet_list,names_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azXYt51q2bOa"
      },
      "outputs": [],
      "source": [
        "#prende il netwoork e bool che falgga normalizzazione e ritorna media della betwennes\n",
        "def average_betwennes(G, normalized):\n",
        "  bet=dict(nx.betweenness_centrality(G,normalized=normalized))\n",
        "  bet_list=list(bet.values())\n",
        "  bet_avg= sum(bet_list)/len(bet_list)\n",
        "  return bet_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD5Gmfph3Njg"
      },
      "outputs": [],
      "source": [
        " #prende il netwoork ritorna media  delle degree dei giocatori\n",
        "def average_degree(G):\n",
        "   degree = dict(G.degree())\n",
        "   degree_list=list(degree.values())\n",
        "   deg_avg = sum(degree_list)/len(degree_list)\n",
        "   return deg_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDxYNzkWpJRl"
      },
      "outputs": [],
      "source": [
        "#Prende in input un networkx graph e ritorna le community trovate con l'algoritmo louvain\n",
        "\n",
        "def CommunityCounting(G):\n",
        "  partition = community_louvain.best_partition(G, random_state=42)\n",
        "  community_labels = {node: community_id for node, community_id in partition.items()}\n",
        "  num_communities = max(community_labels.values()) + 1\n",
        "  return community_labels, num_communities, G.number_of_nodes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJEqzHcE8tOQ"
      },
      "outputs": [],
      "source": [
        "def MostPopulatedCommunity(G):\n",
        "  community_labels, num_communities, nodes = CommunityCounting(G)\n",
        "  num_of_items = Counter(community_labels.values())\n",
        "  num_of_items = dict(num_of_items)\n",
        "  max_comm = max(num_of_items, key=num_of_items.get)\n",
        "  nitems_of_max_community=max(num_of_items.values())\n",
        "  percentage_of_max_comm_items = nitems_of_max_community/(nodes)\n",
        "  return (num_communities, max_comm, nitems_of_max_community, percentage_of_max_comm_items)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2annKiBf_7h_"
      },
      "outputs": [],
      "source": [
        "#fa scatterplot e printa dato il df di partenza, le due colonne che saranno x e y,\n",
        "#la colonna dei labels e quella dei colori.\n",
        "#Si downloada direttamente, non si salva\n",
        "\n",
        "def scatterplot(df,feature1,feature2,labels,color):\n",
        "   fig = px.scatter(data_frame=df, x=feature1, y=feature2, hover_name=labels, color=color)\n",
        "   fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T90gHR4p-jAR"
      },
      "outputs": [],
      "source": [
        "#plotta e salva l'istogramma di un'osservabile coi nomi in verticale e.g. degree dei primi 50 giocatori\n",
        "def plot_histogram_with_vertical_labels(Names_x_axis,observable):\n",
        "   plt.bar(Names_x_axis,observable)\n",
        "   plt.xticks(rotation='vertical')\n",
        "   plt.savefig('./histogram_with_vertical_labels.png')\n",
        "   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95MDnHxYAEs6"
      },
      "outputs": [],
      "source": [
        "#ritorna il coef.angolare, l'intercetta e il coef. di correlazione tra due liste x e y\n",
        "\n",
        "def linear_regression(x,y):\n",
        "   result = linregress(x=x,y=y)\n",
        "   return result.slope,result.intercept,result.rvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qui inizia il processo vero e proprio. La cella immediatamente qui sotto serve a cercare tutti i file .csv nella cartella e salvarsi i nomi, ma volendo si può fare anche a mano se sono pochi.\n"
      ],
      "metadata": {
        "id": "_Vah9Bhg3Zkm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ksEzMoTxAQz"
      },
      "outputs": [],
      "source": [
        "file_names = []\n",
        "for file in glob.glob('./*.csv'):\n",
        "  file_names.append(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questa funzione prende in input una lista di percorsi e un dizionario, loopa sui file e fa tutta l'analisi, restituendo un dizionario.\n",
        "Quelli che non hanno funzionato sono\n",
        "['./chess_data_2005.csv',\n",
        " './chess_data_1990.csv',\n",
        " './chess_data_1995.csv',\n",
        " ]\n",
        "\n"
      ],
      "metadata": {
        "id": "i6wYQiKZ3qVc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9OtH3787V9e"
      },
      "outputs": [],
      "source": [
        "def analisi(file_names, dizionario):\n",
        "\n",
        "  for file in file_names:\n",
        "      try:\n",
        "        df = pd.read_csv(file, low_memory= False)\n",
        "        print('Processando file:', file)\n",
        "\n",
        "        ''' estraggo l'anno dal nome del csv\n",
        "            sfruttando il fatto che sono chess_data_1234.csv.\n",
        "            In questo modo, più giù, posso creare una voce anno nel dizionario\n",
        "            e avere tutti i valori di quell'anno'''\n",
        "\n",
        "        anno = re.match(r\"(.+?)_(\\d+).csv\", file).group(2)\n",
        "        graph = create_network_from_dataframe(df)\n",
        "        G = central_cluster_of_network(graph)\n",
        "        num_nodes = G.number_of_nodes()\n",
        "        num_edges = G.number_of_edges()\n",
        "        diam = (network_diameter(G))\n",
        "        avg_bet = (average_betwennes(G, normalized = True))\n",
        "        avg_deg = (average_degree(G))\n",
        "        num_comm, max_comm, n_items, percentage = MostPopulatedCommunity(G)\n",
        "        dizionario[anno] = {  'max_elements': max_comm,\n",
        "                              'num_comm': num_comm,\n",
        "                              'n_items': n_items,\n",
        "                              'percentage': percentage,\n",
        "                              'avg_deg': avg_deg,\n",
        "                              'avg_bet': avg_bet,\n",
        "                              'diameter': diam,\n",
        "                              'nodes': num_nodes,\n",
        "                              'edges': num_edges,\n",
        "\n",
        "                            }\n",
        "\n",
        "      except Exception as e:\n",
        "        print('Non ha funzionato:' , file)\n",
        "  return(dizionario)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNEd_6SsKEnE"
      },
      "outputs": [],
      "source": [
        "comm_dict = {}\n",
        "analisi(file_names, comm_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAuWK71qdvLT"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame.from_dict(comm_dixt)\n",
        "df.to_csv('dati_terza.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ootz55K4m_ia",
        "outputId": "a4820cd4-3160-4218-9700-5eae63ceefa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2010': {'max_elements': 2,\n",
              "  'num_comm': 21,\n",
              "  'n_items': 120,\n",
              "  'percentage': 0.10118043844856661,\n",
              "  'avg_deg': 5.942664418212479,\n",
              "  'avg_bet': 0.004537599348232893,\n",
              "  'diameter': 18,\n",
              "  'nodes': 1186,\n",
              "  'edges': 3524}}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "comm_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVqRZTAW4KmZ"
      },
      "outputs": [],
      "source": [
        "# DEBUG: qui provo a far calcolare alcune cose. Non hai informazioni su quale funzione dà errore\n",
        "#ma sai quali file sono problematici\n",
        "\n",
        "error_files = []\n",
        "for file in file_names:\n",
        "    try:\n",
        "        df = pd.read_csv(file, low_memory= False)\n",
        "        G2 = create_network_from_dataframe(df)\n",
        "        G = central_cluster_of_network(G2)\n",
        "        diameters.append(network_diameter(G))\n",
        "    except Exception as e:\n",
        "        error_files.append(file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}