{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from scipy.stats import linregress\n"
      ],
      "metadata": {
        "id": "ZHH1swd89T9U"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dataframe(dataframe): #questa funzione pulisce il df eliminando le colonne inutili e droppa i NaN\n",
        "  df = pd.read_csv(dataframe)\n",
        "  new_df = pd.DataFrame(df, columns=['White', 'Black', 'Result', 'Date', 'Opening'])\n",
        "  new_df.dropna()\n",
        "  return new_df\n",
        "\n",
        "\n",
        "def drop_entries_less_than_n(df, columns, n): #questa è la funzione di Luca che crea un nuovo df togliendo le i nodi che hanno degree<n, l'ho tenuta solo per bellezza xk non credo la useremo\n",
        "    combined_list = df[columns].values.flatten().tolist()\n",
        "    count_series = pd.Series(combined_list).value_counts()\n",
        "    count_df = pd.DataFrame({'Element': count_series.index, 'Count': count_series.values})\n",
        "    entries_to_drop = count_df[count_df['Count'] < n]['Element'].tolist()\n",
        "    df = df[~df[columns].apply(lambda x: x[0] in entries_to_drop and x[1] in entries_to_drop, axis=1)]\n",
        "    return df, count_df\n",
        "\n",
        "def create_network_from_dataframe(df): #ritorna il network creato partendo da un df pulito\n",
        "   G = nx.from_pandas_edgelist(df, source='White', target='Black')\n",
        "   return G\n",
        "\n",
        "def draw_and_save_network(G,node_size,with_labels,path): #visualizza e salva in locale un network, prende G, la node-size e un bool se vogliamo mettere o no i labels e il percorso-nome in cui salvare\n",
        "   fig = nx.draw(G, node_size=node_size, with_labels = with_labels)\n",
        "   plt.savefig(path)\n",
        "   plt.show()\n",
        "\n",
        "def plot_histogram_with_vertical_labels(Names_x_axis,observable): #plotta e salva l'istogramma di un'osservabile coi nomi in verticale e.g. degree dei primi 50 giocatori\n",
        "   plt.bar(Names_x_axis,observable)\n",
        "   plt.xticks(rotation='vertical')\n",
        "   plt.savefig('./histogram_with_vertical_labels.png')\n",
        "   plt.show()\n",
        "\n",
        "def network_diameter(G):\n",
        "   return nx.diameter(G)\n",
        "\n",
        "\n",
        "def create_connected_components_of_network(G):\n",
        "   S = [G.subgraph(c).copy() for c in nx.connected_components(G)]\n",
        "   return S\n",
        "\n",
        "def central_cluster_of_network(G):\n",
        "   largest_cc = max(nx.connected_components(G), key=len)\n",
        "   cc = G.subgraph(largest_cc).copy()\n",
        "   return cc\n",
        "\n",
        "def degree_list(G): #questa ritorna 2 liste: la lista delle degree dei giocatori e la lista dei nomi dei giocatori\n",
        "   degree = dict(G.degree())\n",
        "   names_list=list(degree.keys())\n",
        "   degree_list=list(degree.values())\n",
        "   return degree_list,names_list\n",
        "\n",
        "def betweenness_list(G,normalized): #questa prende il network e la bool che dice se vogliamo la betwenness normalizzata o no e ritorna 2 liste: la lista delle betwenness e la lista dei nomi dei giocatori\n",
        "   bet=dict(nx.betweenness_centrality(G,normalized=normalized))\n",
        "   names_list=list(bet.keys())\n",
        "   bet_list=list(bet.values())\n",
        "   return bet_list,names_list\n",
        "\n",
        "def raw_sorting_algorithm(list_to_sort,connected_list): #questa ordina 2 liste. list_to_sort è la lista su cui si ha il controllo dell'ordinamento in senso decrescente, connected_list è la lista collaterale che viene ordinata seguendo l'altra, ritorna le liste ordinate\n",
        "   for i in range(len(list_to_sort)):\n",
        "      for j in range(len(list_to_sort)-1):\n",
        "         if list_to_sort[j]<list_to_sort[j+1]:\n",
        "            var = list_to_sort[j]\n",
        "            list_to_sort[j]=list_to_sort[j+1]\n",
        "            list_to_sort[j+1] = var\n",
        "            var= connected_list[j]\n",
        "            connected_list[j]=connected_list[j+1]\n",
        "            connected_list[j+1] = var\n",
        "   return list_to_sort,connected_list\n",
        "\n",
        "def intersection_of_lists(list1,list2): #ritorna la lista degli elementi in comune tra due liste passate come parametri\n",
        "   intersection=[]\n",
        "   for item in list1:\n",
        "      if item in list2:\n",
        "         intersection.append(item)\n",
        "   return intersection\n",
        "\n",
        "def create_df_with_names_degree_betweenness(Names,degree,betweenness):#prende le liste con nomi,degree e betweenness e ne crea un df\n",
        "   d = {'Name': Names, 'Degree':degree,\n",
        "   'Betweenness':betweenness }\n",
        "   df= pd.DataFrame(data=d)\n",
        "   return df\n",
        "\n",
        "def scatterplot(df,feature1,feature2,labels,color):#fa scatterplot e printa dato il df di partenza, le due colonne che saranno x e y, la colonna dei labels e quella dei colori. Si downloada direttamente, non si salva\n",
        "   fig = px.scatter(data_frame=df, x=feature1, y=feature2, hover_name=labels, color=color)\n",
        "   fig.show()\n",
        "\n",
        "def linear_regression(x,y):#ritorna il coef.angolare, l'intercetta e il coef. di correlazione tra due liste x e y\n",
        "   result = linregress(x=x,y=y)\n",
        "   return result.slope,result.intercept,result.rvalue\n"
      ],
      "metadata": {
        "id": "2wJCiW8D9bIr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2020 = './chess_data_2020.csv'\n",
        "df2020 = clean_dataframe(df2020)\n",
        "G=create_network_from_dataframe(df2020)\n",
        "draw_and_save_network(G,1,False,'./network')\n",
        "central_subgraph=central_cluster_of_network(G)\n",
        "degree_list,names_list=degree_list(G)\n",
        "betweenness_list=betweenness_list(G,True)[0]\n",
        "values_df=create_df_with_names_degree_betweenness(names_list,degree_list,betweenness_list)\n",
        "correl_coefficient=linear_regression(degree_list,betweenness_list)[2]\n",
        "scatterplot(values_df,'Degree','Betweenness','Name','Degree')\n",
        "print(correl_coefficient)"
      ],
      "metadata": {
        "id": "IAaj3Z3D9cZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "file_names = []\n",
        "for file in glob.glob('./*.csv'):\n",
        "  file_names.append(file)\n",
        "file_names"
      ],
      "metadata": {
        "id": "K2tswHT8-6YG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1005f052-756a-467e-b2c7-27eb40041e7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./chess_data_80.csv',\n",
              " './chess_data_95.csv',\n",
              " './chess_data_2000.csv',\n",
              " './chess_data_75.csv',\n",
              " './chess_data_85.csv',\n",
              " './chess_data_70.csv',\n",
              " './chess_data_90.csv',\n",
              " './chess_data_55.csv',\n",
              " './chess_data_50.csv',\n",
              " './chess_data_65.csv',\n",
              " './chess_data_2020.csv',\n",
              " './chess_data_2015.csv',\n",
              " './chess_data_2005.csv',\n",
              " './chess_data_2010.csv',\n",
              " './chess_data_60.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "AOJFqF4kBRYu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_dict = {}\n",
        "for file in file_names[:4]:\n",
        "  df = clean_dataframe(file)\n",
        "  year = re.match(r\"(.+?)_(\\d+).csv\", file).group(2)\n",
        "  print('Processando anno: ', year)\n",
        "  G=create_network_from_dataframe(df)\n",
        "  central_subgraph=central_cluster_of_network(G)\n",
        "  degree_list,names_list=degree_list(G)\n",
        "  betweenness_list=betweenness_list(G,True)[0]\n",
        "  values_df=create_df_with_names_degree_betweenness(names_list,degree_list,betweenness_list)\n",
        "  correl_coefficient=linear_regression(degree_list,betweenness_list)[2]\n",
        "  corr_dict = {year: correl_coefficient}\n",
        "  scatterplot(values_df,'Degree','Betweenness','Name','Degree')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "w3X0Da22_gyv",
        "outputId": "29c893c5-1d3e-48ca-d692-1090c8569c75"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando anno:  80\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-520b15f6d66c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_network_from_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mcentral_subgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentral_cluster_of_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegree_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mbetweenness_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbetweenness_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mvalues_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_df_with_names_degree_betweenness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbetweenness_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
          ]
        }
      ]
    }
  ]
}